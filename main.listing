[gsn]  fas  \end {pythonexample}

\noindent
\begin{minipage}{\linewidth}

  \noindent\textit{example 4:} Plotting multiple columns is as simple
  as adding a more entries to the selection statement

  \lstinputlisting[style=python]{code_examples/dataframes_4.py}
\end{minipage}

\section*{Определение 1.3} Временным рядом \( Y_t \) называется
набор значений траектории случайного процесса,
измеренных в наблюдаемые моменты времени. Он представляет собой
дискретизированную или наблюдаемую версию траектории случайного процесса.

Эквидистантный временной ряд — это последовательность измерений,
сделанных через равные промежутки времени. Однако на практике
интервалы между измерениями часто бывают неравными, особенно в
экономике или при наблюдении за природными явлениями. Например,
данные могут собираться только в рабочие дни, что приводит к
пропускам на выходные и праздники. Эти пропуски нельзя
игнорировать, особенно если временные лаги играют важную роль
(например, при доставке скоропортящихся товаров).
Такие увеличенные интервалы не всегда можно просто выбросить, особенно
если речь идет о непрерывных производствах или фиксированных временных лагах.
Например, если для производства товара А нужен скоропортящийся
товар Б, на доставку которого надо 3 дня, то рост производства Б в
понедельник и вторник отобразится в товаре А на третий рабочий
день, а рост производства Б в пятницу - уже в понедельник (а это
следующая точка, если выходные отброшены).

Главное отличие временного ряда от других типов данных — важность
временного порядка. Не только само значение, но и момент его
измерения имеют значение.

Проводя наблюдения за
каким-то природным явлением, мы вовсе не извлекаем получаемые
значения из одной и той же генеральной совокупности. Даже если
настройки прибора и положение датчиков не менялись, состояние
измеряемого объекта в каждый новый момент времени будет другое.
Попросту говоря, это будет уже другая случайная величина. Серию
измерений, выполненных одним и тем же прибором, даже неподвижно
стоящим под одной и той же горой, нельзя рассматривать, как серию
выборок из одного и того же пространства элементарных событий. Для
описания случайного процесса, в отличие от случайной величины,
недостаточно задать его функцию
распределения один раз. Просто потому, что в разные моменты времени
t она может быть разной. А еще для случайного процесса надо
определить функцию совместного распределения вероятностей для
моментов времени t и t+dt и так далее.

Чтобы оценить эти функции,
наблюдая за случайным процессом, нужна не одна реализация, а целый
ансамбль. Ну, хотя бы десяток реализаций. Причем, это обязательно
должны быть реализации одного и того же случайного процесса. Тогда
и только тогда для каждого момента времени у нас будет несколько
измерений одной и той же случайной величины. Как их обрабатывать
дальше, мы уже знаем из школьного вузовского курса статистики.

Это часто игнорируется при применении
стандартных статистических методов, что может привести к ошибочным
выводам, например, к ложной корреляции между числом пиратов и
глобальным потеплением.

Но что же делать, если у нас есть только одна Земля? Как изучать
взаимосвязи между процессами, каждый из которых мы наблюдаем в
единственном экземпляре?! Проблема эта невероятно сложная,
практически нерешаемая. Мы еще вернемся к ней, когда будем говорить
о свойствах случайных процессов, в частности о стационарности и эргодичности.
Оказывается, что для некоторых классов случайных
процессов, все характеристики которых неизменны во времени, наличие
ансамбля не обязательно! То есть, нам не потребуется десять
реализаций, чтобы оценить какую-нибудь статистику. Вместо этого
достаточно некоторое время понаблюдать за одной! Например, чтобы
оценить коэффициент корреляции между X и Y, достаточно иметь одну
реализацию X и еще одну – Y. Что, собственно, все мы и делаем,
когда вычисляем коэффициент корреляции между потеплением и
пиратами.

Но что же делать с остальными рядами, теми которые не имеют данных
приятных свойств. Рядами с трендами, сезонными и суточными
циклами, и т.д.? Как искать связь между ними и оценивать ее
значимость? На этот вопрос мы в том числе попытаемся найти ответ в
данном учебнике.

Пока же следует запомнить, что общая проблема алгоритмов обработки
временных рядов — это отсутствие математической строгости. Ведь даже когда
мы используем для анализа экспериментальных сигналов алгоритмы со
строгим обоснованием и доказанной оптимальностью, у нас всегда
остается открытым вопрос о том, не нарушены ли условия применимости
таких алгоритмов? Ведь любой алгоритм всегда начинается с преамбулы
(требования), что исходные данные должны обладать вполне
определенными свойствами. Но когда мы имеем дело с
экспериментальным сигналом, доказать выполнение этих требований
почти невозможно. Поэтому было бы наивно думать, что корректность
результата можно гарантировать строгостью метода. На практике
использование строгих методов не дает никаких преимуществ, если с
тем же уровнем строгости не доказана адекватность модели данных, в
рамках которой сформулирован метод. При режимных наблюдениях это
почти невозможно. В лучшем случае можно только предполагать, что
«базовая модель» сигнала вполне адекватна реальным данным. В худшем
(и, к сожалению, более типичном) случае, наоборот, имеются видимые
несоответствия между требованиями теоретической модели и
экспериментальным сигналом. Но если у нас нет уверенности в
адекватности используемой модели данных, это ставит под сомнение и
все результаты, полученные в рамках такой модели.

С одной стороны, такая постановка проблемы может обескуражить -
кажется, что не существует универсального рецепта построения
идеальной модели временного ряда.

С другой стороны, все это дает право на гибкость и вольность мысли.
При изложении материала мы бы хотели, чтобы читатели постоянно
держали в голове связь между временным рядом и свойствами
породившего его случайного процесса.
Мы верим в то, что именно понимание специфических
свойств временного ряда способно привести к пониманию, как
построить наиболее точный и устойчивый прогноз. Как следствие, мы
не хотим делать слишком большой упор на разъяснение механизмов
работы конкретных моделей временных рядов или алгоритмов машинного
обучения. Вместо этого мы бы хотели, чтобы у читателей
сформировалось понимание, какие особенности исходных данных
пытались решить создатели того или иного алгоритма. Сфокусироваться
на исходном problem space, а не на текущем solution space
(тем более, что он постоянно меняется, появляются все новые алгоритмы
  предобработки данных, все новые алгоритмы машинного обучения, схемы
обучения и т.д.).

Не надейтесь, что какая-то типовая модель будет хорошо
аппроксимировать Ваш ряд. Да, в жизни изредка встречаются совершенно стандартные
временные ряды, в точности подходящие под условия применимости той
или иной типовой модели. Но гораздо чаще такого соответствия нет.
Т.е. просто "взять и применить модель" не получится (если, конечно,
нужен хороший результат, а не просто "на, отвяжись"). Вы молодец, что
проверяете качество модели. Однако проблема в том, что хорошие
формальные метрики совершенно не гарантируют, что модель адекватна.
Так как они все на самом деле условны. А именно, полная фраза звучит так:
ЕСЛИ выполнены (список условий) перечисленные условия,
ТО низкая дисперсия остатка говорит о хорошем соответствии модели и данных.
Так вот, на дисперсию остатка смотрят все и всегда, а вот о списке
условий иногда забывают. Хуже того, про него даже в описании моделей
и методик далеко не всегда говорят. Хотя это - ключевой момент. Ведь
если они не выполнены, то и вторая (результирующая) часть тезиса беспредметна.

Пока же вкратце опишем, как же нам жить,
без готовых моделей-то? Базовые принципы примерно таковы:

\begin{enumerate}
  \item Первый совет - если вы хотите глубоко разобраться в структуре
    сигнала и научиться его качественно прогнозировать, не пытайтесь
    применять какие-либо модели к ряду в целом. Сначала разберите ряд на
    детали! То есть, начните с декомпозиции сигнала на составляющие с
    максимально простыми свойствами, по возможности опираясь при этом на
    физику явления. Например, в экономике это может быть тренд, сезонная
    и календарная и/или недельная компоненты, эффекты возмущений
    (праздники и т.п.), разовые ЧЛ (ковид, СВО), квазислучайная
    составляющая и т.д. Чтобы найти и выделить эти компоненты, начните с
    разведочного анализа (для понимания принципов очень советую книжку
      Дж. Тьюки. Да, она очень неторопливая и страшно старая (там даже про
      компьютерные методы ничего еще нет), но зато она простым языком (без
      избытка формул) дает базу.
    \item Затем, зная основные элементы сигнала, выделите каждую
      составляющую в чистом виде. Отдельно - стационарные, отдельно
      нестационарные. После чего можно строить техническую модель каждой
      составляющей, разглядывая ее буквально "под микроскопом". Если вы
      хотите иметь хороший прогноз, то это единственный путь. Ведь хороший
      прогноз - это на самом деле НЕ точный прогноз (как многие ошибочно
      думают), а прогноз с достоверно известной погрешностью, причем очень
      желательно - минимально возможной для данного ряда. А оценка
      погрешности прогноза возможна либо методом "грубой силы" (при наличии
      немеряного количества данных), либо при использовании очень простых
      малопараметрических моделей, где нет хитрых взаимосвязей между
      параметрами. То есть, единственный путь - это максимальное упрощение
      каждой "элементарной модели", из которых потом Вы, как из кирпичиков,
      сложите итоговую конструкцию сигнала.
    \item Вообще, очень многие ряды в принципе не позволяют давать точные
      прогнозы - таковы внутренние свойства сигнала. Да, под такой ряд
      можно очень неплохо подогнать какую-то модель, если у нее достаточно
      много настроечных параметров или (внимание!) вы перепробуете
      достаточно много разных моделей (что по сути эквивалентно добавлению
      неявных параметров в модель - т.н. p-хакинг). Но как только вы
      выйдете за тестовые данные, прогноз даст лажу. Часто совершенно
      неожиданную, ведь данные так хорошо ложились на модель, вроде бы?!
      Это называется "переобучение".
    \item Ключевой момент тут - это поиск закономерностей в сигнале. Все
      "модели" фактически именно этим и занимаются. Причем часто их
      результаты обусловлены базовыми гипотезами. Поясню на простом
      примере. Например, модель может (неявно) формулироваться так:
      ДОПУСТИМ, что наш сигнал состоит из синусоиды и белого шума.
      ТОГДА оптимальный метод оценки параметров этой синусоиды (...длинные
      формулы, которые никто не читает...) и, следовательно, получаем
      ОТВЕТ (...короткие простые формулы, которые дают период, амплитуду и
        фазу искомой синусоиды и их сигмы, и которые мы фактически и
      используем, применяя модель).

      Так вот, основной подвох тут в том, что вместе с "длинными формулами"
      (которые часто действительно можно и не читать) мы сплошь и рядом
      пропускаем вводную часть со словом "ДОПУСТИМ". Хуже того, иногда ее и
      авторы учебников пропускают, полагая самоочевидной и тривиальной...
      Но если наш сигнал не совсем точно удовлетворяет этим "допустим", то
      и результирующие формулы получатся "пальцем в небо". Причем наиболее
      катастрофические ошибки будут в этом случае не в значениях
      параметров, а в их сигмах (стандартных отклонениях). Из-за чего эти
      ошибки становятся очевидными далеко не сразу. Например, если шум на
      самом деле не белый, а броуновский, то описанную выше модель можно
      смело посылать лесом. С реальностью она не будет иметь вообще ничего
      общего. Иначе (если довериться этим оценкам, сделанным в самой
      последней версии самой лучшей программы) мы потом будем с возмущением
      удивляться: как же так, модель идеально подогналась к обучающей
      выборке, прогноз был дан с точностью до 0.01, а в реальности ошибка
      составила 100. Неужели пакет (подставьте название) настолько кривой?
      Да нет, все гораздо проще - мы просто невнимательно прочитали раздел
      "ДОПУСТИМ" и недостаточно хорошо проверили, что наш тестовый сигнал
      ему в точности соответствует... Последнее, кстати, тоже далеко не
      тривиально, особенно если количество/качество данных не совсем такое,
      как нужно...
    \item Ну и еще один "базовый" совет - всегда анализируйте остатки. В
      идеале, они должны быть случайны. Если это не так - значит, модель
      систематически отклоняется от данных. В лучшем случае это значит, что
      в сигнале есть какие-то дополнительные закономерности, которые в
      модели не учтены, и, следовательно, прогноз мог бы быть лучше (если
      их учесть). В худшем - что модель просто кривая (нарушены условия
      применимости и т.д.). Уточню еще, что анализировать остатки надо
      именно по обучающей выборке, а то инет-поиск на "анализ остатков"
    чаще всего выводит на остатки (погрешности) прогноза, что немного другое).
\end{enumerate}

Анализ остатков мы обсудим в следующей секции.

\printbibliography[heading=subbibliography, title={Источники}]
